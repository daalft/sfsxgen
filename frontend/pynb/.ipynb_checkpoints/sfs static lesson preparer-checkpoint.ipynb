{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "numerous-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"sv_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "documented-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "static-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "completed-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesson = \"d:/sfs/lessons/lesson{}.txt\".format(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "electronic-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(\"d:/sfs/lessons/lesson{}.csv\".format(ln), \"w\", encoding=\"utf-8\")\n",
    "with open(lesson, \"r\", encoding=\"utf-8\") as f:\n",
    "    for l in f:\n",
    "        if not l.strip():\n",
    "            continue\n",
    "        if l.startswith(\"#\"):  # title\n",
    "            title = l.rstrip()[1:]\n",
    "            out.write(title)\n",
    "            out.write(\"\\n\")\n",
    "            continue\n",
    "        l = l.rstrip()\n",
    "        sent = nlp(l)\n",
    "        \n",
    "        for o,token in enumerate(sent):\n",
    "            pos = token.pos_\n",
    "            t = token.text\n",
    "            lemma = token.lemma_\n",
    "            out.write(\"{}\\t{}\\t{}\\n\".format(t, pos, lemma))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "technical-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "viral-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpos = \"PRON\"\n",
    "tf = \"token\"\n",
    "res = {\"targets\": [], \"tokens\": [], \"title\": None}\n",
    "spacer_obj = {\"word\": \" \"}\n",
    "with open(\"d:/sfs/lessons/lesson{}.csv\".format(ln), \"r\", encoding=\"utf-8\") as f:\n",
    "    title = f.readline()\n",
    "    res[\"title\"] = title\n",
    "    for l in f:\n",
    "        if not l.strip():\n",
    "            continue\n",
    "        ps = l.rstrip().split(\"\\t\")\n",
    "        nobj = dict()\n",
    "        nobj[\"word\"] = ps[0]\n",
    "        nobj[\"lemma\"] = ps[2]\n",
    "        target = ps[2].lower() if tf == \"lemma\" else ps[0].lower()\n",
    "        \n",
    "        if ps[1] == tpos:\n",
    "            nobj[\"gap\"] = True\n",
    "            if target not in res[\"targets\"]:\n",
    "                res[\"targets\"].append(target)\n",
    "            accepted = None\n",
    "            try:\n",
    "                accepted = [ps[0]]\n",
    "                accepted.extend(ps[3].split(\",\"))\n",
    "            except:\n",
    "                accepted = [target]\n",
    "            \n",
    "            nobj[\"accept\"] = accepted\n",
    "        res[\"tokens\"].append(nobj)\n",
    "        res[\"tokens\"].append(spacer_obj)\n",
    "#pickle.dump(res, open(\"D:/sfs/sfsxgen/src/assets/lesson{}_{}_{}.pickle\".format(ln, tpos, tf), \"wb\"))\n",
    "json.dump(res, open(\"D:/sfs/sfsxgen/src/assets/lesson{}_{}_{}.json\".format(ln, tpos, tf), \"w\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "twelve-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dict()\n",
    "posses = [\"NOUN\", \"PRON\", \"VERB\", \"ADJ\", \"NUM\"]\n",
    "for p in posses:\n",
    "    res[p] = dict()\n",
    "    res[p][\"gapped\"] = []\n",
    "    res[p][\"target\"] = []\n",
    "    res[p][\"title\"] = \"\"\n",
    "with open(\"d:/sfs/lessons/lesson{}.csv\".format(ln), \"r\", encoding=\"utf-8\") as f:\n",
    "    title = f.readline()\n",
    "    for l in f:\n",
    "        if not l.strip():\n",
    "            continue\n",
    "        ps = l.rstrip().split(\"\\t\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "limiting-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(res, open(\"d:/sfs/lessons/lesson1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "serious-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Hej'},\n",
       " {'word': 'Hej'},\n",
       " {'word': 'namn'},\n",
       " {'word': 'Tack'},\n",
       " {'word': 'svenska'},\n",
       " {'word': 'engelska'},\n",
       " {'word': 'tyska'},\n",
       " {'word': 'språk'},\n",
       " {'word': 'ukrainska'},\n",
       " {'word': 'engelska'},\n",
       " {'word': 'telefon'},\n",
       " {'word': 'nummer'},\n",
       " {'word': 'tack'},\n",
       " {'word': 'nummer'},\n",
       " {'word': 'nummer'},\n",
       " {'word': 'nummer'},\n",
       " {'word': 'tack'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"NOUN\"][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "elder-relation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vad heter du?'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "rural-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Ja! Mitt nummer är 012-45-67-89: noll, ett, två, fyra, fem, sex sju, åtta, nio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dangerous-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ja INTJ ROOT ja\n",
      "! PUNCT punct !\n",
      "Mitt PRON nmod:poss Mitt\n",
      "nummer NOUN nsubj nummer\n",
      "är AUX cop vara\n",
      "012-45-67-89 ADJ ROOT 012-45-67-89\n",
      ": PUNCT punct :\n",
      "noll NUM obl noll\n",
      ", PUNCT punct ,\n",
      "ett NUM conj en\n",
      ", PUNCT punct ,\n",
      "två NUM conj två\n",
      ", PUNCT punct ,\n",
      "fyra NUM conj fyra\n",
      ", PUNCT punct ,\n",
      "fem NUM conj fem\n",
      ", PUNCT punct ,\n",
      "sex NUM obl sex\n",
      "sju NUM conj sju\n",
      ", PUNCT punct ,\n",
      "åtta NUM nmod åtta\n",
      ", PUNCT punct ,\n",
      "nio NUM conj nio\n",
      ". PUNCT punct .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-bench",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
